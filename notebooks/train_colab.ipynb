{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphSAGE Training for Memory R1\n",
    "\n",
    "This notebook trains GraphSAGE for structural embeddings using the random walk co-occurrence approach.\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU runtime (T4 or L4)\n",
    "- PyTorch Geometric installed\n",
    "\n",
    "**Training Pipeline:**\n",
    "1. Generate/load graph data\n",
    "2. Extract GraphSAGE view and features\n",
    "3. Generate random walks and pairs\n",
    "4. Train model with skip-gram objective\n",
    "5. Evaluate and export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch Geometric if not already installed\n",
    "try:\n",
    "    import torch_geometric\n",
    "    print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Installing PyTorch Geometric...\")\n",
    "    !pip install torch-geometric -q\n",
    "    import torch_geometric\n",
    "    print(f\"Installed PyTorch Geometric: {torch_geometric.__version__}\")\n",
    "\n",
    "!git clone https://github.com/celestice106/graphsage\n",
    "%cd graphsage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install other requirements\n",
    "!pip install pyyaml scikit-learn matplotlib tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"WARNING: No GPU available. Training will be slow.\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project to path (adjust if needed)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# If running from notebooks folder\n",
    "project_root = Path('.').absolute().parent\n",
    "if (project_root / 'src').exists():\n",
    "    sys.path.insert(0, str(project_root))\n",
    "else:\n",
    "    # If running from project root\n",
    "    project_root = Path('.').absolute()\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import load_config\n",
    "\n",
    "# Load default config\n",
    "config = load_config()\n",
    "\n",
    "# Override for Colab training\n",
    "config['training']['device'] = 'cuda'\n",
    "config['training']['batch_size'] = 1024  # Larger batch for GPU\n",
    "config['training']['epochs'] = 100\n",
    "config['training']['log_every'] = 5\n",
    "\n",
    "# Print key settings\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Walk length: {config['walks']['length']}\")\n",
    "print(f\"  Walks per node: {config['walks']['per_node']}\")\n",
    "print(f\"  Context window: {config['walks']['context_window']}\")\n",
    "print(f\"  Hidden dim: {config['model']['hidden_dim']}\")\n",
    "print(f\"  Output dim: {config['model']['output_dim']}\")\n",
    "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create/Load Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import GraphSAGEDataset, GraphLoader\n",
    "\n",
    "# Configuration for graph generation\n",
    "NUM_MEMORIES = 500  # Number of memory nodes\n",
    "NUM_ENTITIES = 100  # Number of entity nodes\n",
    "SEED = 42\n",
    "\n",
    "# Create synthetic graph (or load from file)\n",
    "print(\"Creating synthetic graph...\")\n",
    "dataset = GraphSAGEDataset.from_mock(\n",
    "    num_memories=NUM_MEMORIES,\n",
    "    num_entities=NUM_ENTITIES,\n",
    "    seed=SEED,\n",
    "    undirected=True\n",
    ")\n",
    "\n",
    "# Get statistics\n",
    "stats = dataset.get_statistics()\n",
    "print(f\"\\nGraph Statistics:\")\n",
    "print(f\"  Nodes: {stats['num_nodes']}\")\n",
    "print(f\"  Edges: {stats['num_edges']}\")\n",
    "print(f\"  Avg degree: {stats['avg_degree']:.2f}\")\n",
    "print(f\"  Density: {stats['density']:.4f}\")\n",
    "print(f\"  Isolated nodes: {stats['isolated_nodes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to GPU\n",
    "data = dataset.get_data(device=device)\n",
    "\n",
    "print(f\"Features shape: {data.x.shape}\")\n",
    "print(f\"Edge index shape: {data.edge_index.shape}\")\n",
    "print(f\"Data on: {data.x.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Random Walks and Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.walks import RandomWalkGenerator, CooccurrencePairSampler, DegreeBiasedNegativeSampler\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "walk_config = config['walks']\n",
    "\n",
    "print(\"Generating random walks...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create walker (works on CPU for efficiency)\n",
    "walker = RandomWalkGenerator(\n",
    "    edge_index=data.edge_index.cpu(),\n",
    "    num_nodes=data.num_nodes,\n",
    "    walk_length=walk_config['length'],\n",
    "    walks_per_node=walk_config['per_node'],\n",
    "    seed=walk_config['seed']\n",
    ")\n",
    "\n",
    "walks = walker.generate_all_walks(verbose=True)\n",
    "\n",
    "print(f\"\\nGenerated {len(walks)} walks in {time.time() - start_time:.2f}s\")\n",
    "print(f\"Average walk length: {sum(len(w) for w in walks) / len(walks):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract co-occurrence pairs\n",
    "print(\"\\nExtracting positive pairs...\")\n",
    "start_time = time.time()\n",
    "\n",
    "pair_sampler = CooccurrencePairSampler(\n",
    "    context_window=walk_config['context_window']\n",
    ")\n",
    "pairs = pair_sampler.extract_pairs(walks)\n",
    "\n",
    "print(f\"Extracted {len(pairs):,} pairs in {time.time() - start_time:.2f}s\")\n",
    "\n",
    "# Get pair statistics\n",
    "pair_stats = pair_sampler.get_statistics(walks)\n",
    "print(f\"Unique pairs: {pair_stats['unique_pairs']:,}\")\n",
    "print(f\"Avg contexts per target: {pair_stats['avg_contexts_per_target']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create negative sampler\n",
    "neg_config = config['negatives']\n",
    "\n",
    "neg_sampler = DegreeBiasedNegativeSampler(\n",
    "    edge_index=data.edge_index,\n",
    "    num_nodes=data.num_nodes,\n",
    "    exponent=neg_config['exponent'],\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Negative sampler ready (exponent={neg_config['exponent']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import ProductionGraphSAGE\n",
    "\n",
    "model_config = config['model']\n",
    "feature_dim = config['features']['dimensions']\n",
    "\n",
    "model = ProductionGraphSAGE(\n",
    "    in_channels=feature_dim,\n",
    "    hidden_channels=model_config['hidden_dim'],\n",
    "    out_channels=model_config['output_dim'],\n",
    "    num_layers=model_config['num_layers'],\n",
    "    dropout=model_config['dropout'],\n",
    "    normalize_output=model_config['normalize_output']\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model created:\")\n",
    "print(f\"  Parameters: {model.count_parameters():,}\")\n",
    "print(f\"  Input dim: {feature_dim}\")\n",
    "print(f\"  Hidden dim: {model_config['hidden_dim']}\")\n",
    "print(f\"  Output dim: {model_config['output_dim']}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import GraphSAGETrainer\n",
    "\n",
    "# Create output directories\n",
    "import os\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# Update paths in config\n",
    "config['paths']['checkpoints'] = 'checkpoints'\n",
    "config['paths']['logs'] = 'logs'\n",
    "\n",
    "# Create trainer\n",
    "trainer = GraphSAGETrainer(\n",
    "    model=model,\n",
    "    features=data.x,\n",
    "    edge_index=data.edge_index,\n",
    "    positive_pairs=pairs,\n",
    "    negative_sampler=neg_sampler,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "train_config = config['training']\n",
    "num_epochs = train_config['epochs']\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_loss = trainer.train(num_epochs=num_epochs)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training complete! Best loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.metrics import evaluate_embeddings, check_embedding_health\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = trainer.get_embeddings()\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Health check\n",
    "is_healthy, issues = check_embedding_health(embeddings)\n",
    "print(f\"\\nHealth check: {'PASSED' if is_healthy else 'FAILED'}\")\n",
    "if issues:\n",
    "    for issue in issues:\n",
    "        print(f\"  - {issue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full evaluation\n",
    "results = evaluate_embeddings(embeddings, data.edge_index)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Evaluation Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nNeighbor Similarity:\")\n",
    "print(f\"  Connected pairs: {results['neighbor_similarity']['neighbor_sim_mean']:.4f}\")\n",
    "print(f\"  Random pairs: {results['neighbor_similarity']['random_sim_mean']:.4f}\")\n",
    "print(f\"  Gap: {results['neighbor_similarity']['sim_gap']:.4f}\")\n",
    "\n",
    "print(f\"\\nLink Prediction:\")\n",
    "print(f\"  AUC-ROC: {results['link_prediction']['auc_roc']:.4f}\")\n",
    "print(f\"  Avg Precision: {results['link_prediction']['avg_precision']:.4f}\")\n",
    "\n",
    "print(f\"\\nEmbedding Quality:\")\n",
    "print(f\"  Normalized: {results['embedding_stats']['is_normalized']}\")\n",
    "print(f\"  Collapsed: {results['embedding_stats']['is_collapsed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.visualization import plot_embeddings_tsne, plot_similarity_distribution\n",
    "\n",
    "# t-SNE visualization\n",
    "print(\"Creating t-SNE visualization...\")\n",
    "plot_embeddings_tsne(\n",
    "    embeddings,\n",
    "    output_path='embeddings_tsne.png',\n",
    "    show=True,\n",
    "    sample_size=300  # Sample for faster visualization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity distribution\n",
    "print(\"Creating similarity distribution plot...\")\n",
    "plot_similarity_distribution(\n",
    "    embeddings,\n",
    "    data.edge_index,\n",
    "    output_path='similarity_distribution.png',\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('exports', exist_ok=True)\n",
    "\n",
    "# Save for production use\n",
    "export_path = 'exports/graphsage_production.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': config,\n",
    "    'embedding_dim': model.out_channels,\n",
    "    'in_channels': model.in_channels,\n",
    "    'best_loss': best_loss,\n",
    "    'evaluation': results\n",
    "}, export_path)\n",
    "\n",
    "print(f\"Model exported to: {export_path}\")\n",
    "print(f\"File size: {os.path.getsize(export_path) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import MemoryR1StructuralEncoder\n",
    "\n",
    "# Create encoder from exported model\n",
    "encoder = MemoryR1StructuralEncoder(\n",
    "    model_path=export_path,\n",
    "    device='cuda',\n",
    "    cache_embeddings=True\n",
    ")\n",
    "\n",
    "# Test inference\n",
    "test_embeddings = encoder.encode_all(dataset.full_graph)\n",
    "\n",
    "print(f\"Inference successful!\")\n",
    "print(f\"Embeddings shape: {test_embeddings.shape}\")\n",
    "print(f\"Embedding dim: {encoder.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark inference\n",
    "import time\n",
    "\n",
    "# Warm up\n",
    "for _ in range(5):\n",
    "    _ = encoder.encode_all(dataset.full_graph, force_recompute=True)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Benchmark\n",
    "times = []\n",
    "for _ in range(50):\n",
    "    start = time.perf_counter()\n",
    "    _ = encoder.encode_all(dataset.full_graph, force_recompute=True)\n",
    "    torch.cuda.synchronize()\n",
    "    times.append(time.perf_counter() - start)\n",
    "\n",
    "import numpy as np\n",
    "times_ms = [t * 1000 for t in times]\n",
    "\n",
    "print(f\"\\nInference Benchmark:\")\n",
    "print(f\"  Mean: {np.mean(times_ms):.2f} ms\")\n",
    "print(f\"  Std: {np.std(times_ms):.2f} ms\")\n",
    "print(f\"  Min: {np.min(times_ms):.2f} ms\")\n",
    "print(f\"  Max: {np.max(times_ms):.2f} ms\")\n",
    "print(f\"  Throughput: {1000 / np.mean(times_ms):.1f} inferences/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training complete! The model is exported and ready for use with Memory R1.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Download `exports/graphsage_production.pt` for use in Memory R1\n",
    "2. Or save to Google Drive for persistence:\n",
    "   ```python\n",
    "   from google.colab import drive\n",
    "   drive.mount('/content/drive')\n",
    "   !cp exports/graphsage_production.pt /content/drive/MyDrive/\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
